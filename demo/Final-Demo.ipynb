{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Year Project: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing drug use in the UK through Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  These two blocks are responsible for iterating through mongoDB, ignoring tweets without coordinate & place data (1 mil approx tweets) and adding them to a list. SKIP THESE TWO MODULES, GO STRAIGHT TO SUBSTITUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from collections import Counter\n",
    "import pprint\n",
    "\n",
    "# connects to local MongoDB \n",
    "client = MongoClient()\n",
    "db = client[\"twitter_db\"]\n",
    "collection = db.twitter_testset\n",
    "\n",
    "\n",
    "# Lists for holding tweets \n",
    "tweets = []\n",
    "filteredTweets = []\n",
    "newleyFilteredTweets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "# iterates through mongoDB collection, adding a dictionary object to a list\n",
    "for obj in collection.find():\n",
    "    if obj['text'] is None:\n",
    "        continue\n",
    "    if obj['geo'] is None:\n",
    "        continue\n",
    "    if obj['place'] is None:\n",
    "        continue\n",
    "    tweet = {}\n",
    "    tweet['text'] = obj['text']\n",
    "    tweet['geo'] = obj['geo']['coordinates']\n",
    "    tweet['place'] = obj['place']['name']\n",
    "    tweets.append(tweet)\n",
    "print(str(len(tweets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This block is the substitute for mongoDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# to save (change protocol=3 to protocol=2 if in python 2.x)\n",
    "# with open('testSet.pkl', 'wb') as f:\n",
    "  #   pickle.dump(tweets, f, protocol=2)\n",
    "    \n",
    "# to load\n",
    "with open(\"testSet.pkl\", \"rb\") as f:\n",
    "    tweets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Heat map before filtration (don't use in demo, is a bit laggy due to quantity of tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gmaps.datasets\n",
    "coord = []\n",
    "\n",
    "# convert dictionary entries to array for gmaps\n",
    "for tweet in tweets:\n",
    "    coord.append(tweet['geo'])\n",
    "    \n",
    "gmaps.configure(api_key=\"AIzaSyADv13vyns8lTpdjwoxMwYL3Q0k2Eqoyno\")\n",
    "locations = coord\n",
    "fig = gmaps.figure()\n",
    "fig.add_layer(gmaps.heatmap_layer(locations))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This block filters for drug related tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Amount of tweets before filtering: ' + str(len(tweets)))\n",
    "filteredTweets = []\n",
    "newleyFilteredTweets = []\n",
    "\n",
    "# collection of keywords split by drug.\n",
    "keywordWeed = ['weed', 'marijuana', 'stoned', 'blazed', '420', 'mary jane','devil\\'s lettuce', 'devils lettuce', 'dank',\n",
    "               'doobie', 'kush']\n",
    "keywordCocaine = ['cocaine','charlie', 'blow', '8 ball', 'nose candy', 'white powder', 'snow white', 'yayo']\n",
    "keywordEcstasy = ['ecstasy','molly','mandy',' rolling','mdma', 'XTC','xtc','e pill','rave']\n",
    "keywordAmphetamines = ['whizz', 'sulph', 'paste' , 'billy' , 'base', 'uppers']\n",
    "keywordHallucinogens = ['lsd', 'LSD',' shrooms', 'magic mushrooms', 'liberty cap', 'mushies', 'acid', 'blotter']\n",
    "\n",
    "keywordAll = keywordWeed + keywordCocaine + keywordEcstasy + keywordAmphetamines + keywordHallucinogens\n",
    "\n",
    "# To change the filter used, assign keyword to a different list above. \n",
    "keywords = keywordAll\n",
    "\n",
    "for tweet in tweets:\n",
    "    if any(word in tweet['text'] for word in keywords):\n",
    "        filteredTweets.append(tweet)\n",
    "print('Amount of tweets matching keywords: ' + str(len(filteredTweets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second round of filtering to remove false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywordsR = ['garden', 'Garden', 'boot', 'weeds', 'model', 'education', 'weather', 'Weather', 'tweed', 'Tweed', 'weeding',\n",
    "             'seaweed', 'Seaweed', 'Stigmabase', 'travel', 'Travel', 'nutrition', 'based', 'gravel']\n",
    "# list comprehension to make sure no skips in the iterations\n",
    "for tweet in filteredTweets:\n",
    "    if not any(word in tweet['text'] for word in keywordsR):\n",
    "        newleyFilteredTweets.append(tweet)\n",
    "filteredTweets = newleyFilteredTweets\n",
    "\n",
    "print('Amount of tweets after additional filtering: ' + str(len(filteredTweets)))\n",
    "\n",
    "del(newleyFilteredTweets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  HeatMap block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gmaps.datasets\n",
    "coord = []\n",
    "# convert dictionary entries to array for gmaps\n",
    "for tweet in filteredTweets:\n",
    "    coord.append(tweet['geo'])\n",
    "    \n",
    "gmaps.configure(api_key=\"AIzaSyADv13vyns8lTpdjwoxMwYL3Q0k2Eqoyno\")\n",
    "locations = coord\n",
    "fig = gmaps.figure()\n",
    "fig.add_layer(gmaps.heatmap_layer(locations))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Counts all places and lists them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from collections import Counter\n",
    "\n",
    "# below gets a list of places for categorisation\n",
    "places = []\n",
    "for tweet in filteredTweets:\n",
    "    places.append(tweet['place'])\n",
    "    # print(tweet['text'] + \" ( \" + tweet['place'] + ' )')\n",
    "pprint.pprint(Counter(places))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Greater area counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "northEast = ['County Durham', 'Durham',  'Darlington', 'Gateshead', 'Hartlepool', 'Middlesbrough', 'Newcastle', 'North Tyneside', \n",
    "             'Northumberland', 'Redcar and Cleveland', 'South Tyneside', 'Stockton-on-Tees', 'Sunderland', 'North East']\n",
    "\n",
    "northWest = ['Blackburn with Darwen', 'Blackpool', 'Bolton' ,'Bury', 'Cheshire East', 'Cheshire West', 'Chester', 'Cumbria',\n",
    "             'Halton', 'Knowsley', 'Lancashire', 'Liverpool', 'Manchester', 'Oldham', 'Rochdale', 'Salford', 'Sefton', \n",
    "             'St. Helens', 'Stockport', 'Tameside', 'Trafford', 'Warrington', 'Wigan', 'Wirral', 'North West',\n",
    "             'Ashton-under-Lyne']\n",
    "\n",
    "yorkshireAndTheHumber = ['Barnsley', 'Bradford' , 'Calderdale', 'Doncaster', 'East Riding of Yorkshire', 'Kingston upon Hull',\n",
    "                         'Kirklees', 'Leeds', 'North East', 'Lincolnshire', 'Lincolnshire North', 'Yorkshire', \n",
    "                         'Rotherham', 'Sheffield', 'Wakefield', 'York']\n",
    "\n",
    "eastMidlands = ['Derby', 'Derbyshire', 'Leicester', 'Leicestershire', 'Lincoln', 'Northampton', 'Nottingham', \n",
    "                'Nottinghamshire', 'Rutland', 'East Midlands', 'Loughborough']\n",
    "\n",
    "westMidlands = ['Birmingham', 'Coventry', 'Dudley', 'Herefordshire', 'Sandwell', 'Shropshire', 'Solihull', 'Staffordshire', \n",
    "                'Stoke-on-Trent', 'Telford', 'Wrekin', 'Walsall', 'Warwickshire', 'Wolverhampton', 'Worcestershire', 'Worcester',\n",
    "                'West Midlands', 'Stoke']\n",
    "\n",
    "eastOfEngland = ['Bedford', 'East', 'Cambridgeshire', 'Bedfordshire', 'Essex', 'Norwich', 'Cambridge',\n",
    "                 'Hertfordshire', 'Luton', 'Norfolk', 'Peterborough', 'Hertford', 'Bedford',\n",
    "                 'Southend-on-Sea', 'Suffolk Thurrock']\n",
    "\n",
    "London = ['Gravesend', 'Grays', 'Barking', 'Dagenham', 'Barnet', 'Bexley', 'Brent', 'Bromley', 'Camden Town', 'London',\n",
    "          'Croydon', 'Ealing', 'Enfield', 'Greenwich', 'Hackney', 'Hammersmith', 'Fulham', 'Haringey', 'Harrow', 'Havering', \n",
    "          'Hillingdon', 'Hounslow', 'Islington', 'Kensington', 'Chelsea', 'Kingston upon Thames', 'Walthamstow',\n",
    "          'Lambeth', 'Lewisham', 'Merton', 'Newham', 'Poplar', 'Paddington', 'Camberwell', 'Tottenham',\n",
    "          'Redbridge', 'Richmond', 'Southwark', 'Sutton', 'Tower Hamlets', 'Waltham Forest', 'Wandsworth', \n",
    "          'Westminster']\n",
    "\n",
    "southEast = ['South East', 'Bracknell Forest', 'Brighton', 'Hove', 'Buckingham', 'Sussex', 'Hampshire', \n",
    "             'Isle of Wight', 'Kent', 'Worthing',\n",
    "             'Medway', 'Milton Keynes', 'Oxford', 'Portsmouth', 'Reading', 'Slough', 'Southampton', 'Surrey', \n",
    "             'Berkshire', 'Sussex', 'Windsor', 'Maidenhead', 'Wokingham']\n",
    "\n",
    "southWest = ['South West', 'Bath', 'Somerset', 'Bournemouth', 'Bristol', 'Cornwall', 'Devon', 'Dorset', \n",
    "             'Gloucestershire', 'Isles of Scilly', 'Exeter',\n",
    "             'Plymouth', 'Poole', 'Swindon', 'Torbay', 'Wiltshire']\n",
    "\n",
    "Ireland = ['Dublin', 'Ireland', 'Belfast', 'Fingal','Northern Ireland', 'South Dublin','Dun Laoghaire-Rathdown']\n",
    "Scotland = ['Glasgow','Scotland']\n",
    "Wales = ['Wales', 'Cardiff', 'Swansea']\n",
    "           \n",
    "northEastCount = 0\n",
    "northWestCount = 0\n",
    "yorkshireAndTheHumberCount = 0\n",
    "eastMidlandsCount = 0\n",
    "westMidlandsCount = 0\n",
    "eastOfEnglandCount = 0\n",
    "LondonCount = 0\n",
    "southEastCount = 0\n",
    "southWestCount = 0\n",
    "irelandCount = 0\n",
    "scotlandCount = 0\n",
    "walesCount = 0\n",
    "\n",
    "for tweet in filteredTweets:\n",
    "    if any (word in tweet['place'] for word in northEast):\n",
    "        northEastCount += 1 \n",
    "    elif any (word in tweet['place'] for word in northWest):\n",
    "        northWestCount += 1\n",
    "    elif any (word in tweet['place'] for word in yorkshireAndTheHumber):\n",
    "        yorkshireAndTheHumberCount += 1\n",
    "    elif any (word in tweet['place'] for word in eastMidlands):\n",
    "        eastMidlandsCount += 1\n",
    "    elif any (word in tweet['place'] for word in westMidlands):\n",
    "        westMidlandsCount += 1\n",
    "    elif any (word in tweet['place'] for word in eastOfEngland):\n",
    "        eastOfEnglandCount += 1\n",
    "    elif any (word in tweet['place'] for word in London):\n",
    "        LondonCount += 1\n",
    "    elif any (word in tweet['place'] for word in southEast):\n",
    "        southEastCount += 1        \n",
    "    elif any (word in tweet['place'] for word in southWest):\n",
    "        southWestCount += 1\n",
    "    elif any (word in tweet['place'] for word in Ireland):\n",
    "        irelandCount += 1\n",
    "    elif any (word in tweet['place'] for word in Scotland):\n",
    "        scotlandCount += 1\n",
    "    elif any (word in tweet['place'] for word in Wales):\n",
    "        walesCount += 1\n",
    "        \n",
    "\n",
    "allCount = northEastCount + northWestCount + yorkshireAndTheHumberCount + eastMidlandsCount + westMidlandsCount + eastOfEnglandCount + LondonCount + southEastCount + southWestCount + irelandCount + scotlandCount + walesCount\n",
    "\n",
    "print('North East:', northEastCount)\n",
    "print('North West:', northWestCount)\n",
    "print('Yorkshire and the Humber:', yorkshireAndTheHumberCount)\n",
    "print('East Midlands:', eastMidlandsCount)\n",
    "print('West Midlands:', westMidlandsCount)\n",
    "print('East Of England:', eastOfEnglandCount)\n",
    "print('London:', LondonCount)\n",
    "print('South East:', southEastCount)\n",
    "print('South West:', southWestCount)\n",
    "print('Ireland:', irelandCount)\n",
    "print('Scotland:', scotlandCount)\n",
    "print('Wales:', walesCount)\n",
    "print('All:', allCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
